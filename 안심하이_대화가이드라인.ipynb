{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 필요한 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.51.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting soundfileNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Downloading soundfile-0.12.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.0 MB 991.0 kB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.2/1.0 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.4/1.0 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.0/1.0 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 5.3 MB/s eta 0:00:00\n",
      "Installing collected packages: soundfile\n",
      "Successfully installed soundfile-0.12.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.10)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.9/64.9 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl (100 kB)\n",
      "   ---------------------------------------- 0.0/100.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 100.4/100.4 kB 5.6 MB/s eta 0:00:00\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "   ---------------------------------------- 0.0/126.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 126.3/126.3 kB 7.7 MB/s eta 0:00:00\n",
      "Installing collected packages: urllib3, charset-normalizer, requests\n",
      "Successfully installed charset-normalizer-3.3.2 requests-2.32.3 urllib3-2.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-2.1.1-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "     ---------------------------------------- 0.0/59.7 kB ? eta -:--:--\n",
      "     ------------- -------------------------- 20.5/59.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 59.7/59.7 kB 785.8 kB/s eta 0:00:00\n",
      "Downloading numpy-2.1.1-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/12.6 MB 3.6 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.0/12.6 MB 22.0 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 1.0/12.6 MB 22.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.1/12.6 MB 20.1 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.1/12.6 MB 20.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.0/12.6 MB 32.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.5/12.6 MB 46.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.5/12.6 MB 46.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.5/12.6 MB 46.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.5/12.6 MB 46.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.5/12.6 MB 46.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.5/12.6 MB 46.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.5/12.6 MB 46.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 23.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 21.8 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "import threading\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import time\n",
    "from pydub import AudioSegment\n",
    "import requests\n",
    "import json\n",
    "import base64\n",
    "import urllib3\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "client = OpenAI(api_key='sk-VsBg3163eZFviFyybH3yorlp8TE5WlPQOeh_qUjLReT3BlbkFJ-ZZNFazlMsQ2_JF28W1TIgfbG9_B_a7nnASC8VBnYA')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 전역 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = queue.Queue()\n",
    "recording = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 실시간 녹음 함수 및 콜백 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complicated_record():\n",
    "    with sf.SoundFile(\"temp.wav\", mode='w', samplerate=16000, subtype='PCM_16', channels=1) as file:\n",
    "        with sd.InputStream(samplerate=16000, dtype='int16', channels=1, callback=complicated_save):\n",
    "            while recording:\n",
    "                file.write(q.get())\n",
    "\n",
    "def complicated_save(indata, frames, time, status):\n",
    "    q.put(indata.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 녹음 시작 및 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_recording():\n",
    "    global recording\n",
    "    recording = True\n",
    "    recorder = threading.Thread(target=complicated_record)\n",
    "    print('Start recording')\n",
    "    recorder.start()\n",
    "    return recorder\n",
    "\n",
    "def stop_recording(recorder):\n",
    "    global recording\n",
    "    recording = False\n",
    "    recorder.join()\n",
    "    print('Stop recording')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. STT 변환 및 파일 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio_and_send(file_path, segment_length=20000):\n",
    "    audio = AudioSegment.from_wav(file_path)\n",
    "    duration = len(audio)\n",
    "    full_text = \"\"\n",
    "    \n",
    "    for i in range(0, duration, segment_length):\n",
    "        segment = audio[i:i + segment_length]\n",
    "        segment_path = f\"segment_{i//1000}.wav\"\n",
    "        segment.export(segment_path, format=\"wav\")\n",
    "        text = send_to_stt(segment_path)\n",
    "        full_text += text + \" \"\n",
    "        \n",
    "        if os.path.exists(segment_path):\n",
    "            os.remove(segment_path)\n",
    "\n",
    "    return full_text.strip()\n",
    "\n",
    "def send_to_stt(segment_path):\n",
    "    openApiURL = \"http://aiopen.etri.re.kr:8000/WiseASR/Recognition\"\n",
    "    accessKey = \"your-etri-access-key\"\n",
    "    languageCode = \"korean\"\n",
    "\n",
    "    with open(segment_path, \"rb\") as file:\n",
    "        audioContents = base64.b64encode(file.read()).decode(\"utf8\")\n",
    "    \n",
    "    requestJson = {\n",
    "        \"argument\": {\n",
    "            \"language_code\": languageCode,\n",
    "            \"audio\": audioContents\n",
    "        }\n",
    "    }\n",
    "\n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request(\n",
    "        \"POST\",\n",
    "        openApiURL,\n",
    "        headers={\"Content-Type\": \"application/json; charset=UTF-8\", \"Authorization\": accessKey},\n",
    "        body=json.dumps(requestJson)\n",
    "    )\n",
    "    \n",
    "    response_data = json.loads(response.data.decode('utf-8'))\n",
    "    return response_data.get(\"return_object\", {}).get(\"recognized\", \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. GPT로 대화 방향성 조언 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_advice(conversation_text):\n",
    "    # GPT 모델에게 보내는 메시지 형식\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant providing conversation guidance for welfare services.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Here is the conversation so far: {conversation_text}. What should be the next step to provide the best advice and support?\"}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",  # Chat-based GPT 모델\n",
    "        messages=messages,\n",
    "        max_tokens=300,\n",
    "        temperature=0.7,\n",
    "        top_p=1.0,\n",
    "        n=1\n",
    "    )\n",
    "    \n",
    "    # GPT의 응답 반환\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 메인 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-104 (complicated_record):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_2600\\3078862851.py\", line 3, in complicated_record\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sounddevice.py\", line 1429, in __init__\n",
      "    _StreamBase.__init__(self, kind='input', wrap_callback='array',\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sounddevice.py\", line 777, in __init__\n",
      "    import numpy\n",
      "ModuleNotFoundError: No module named 'numpy'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start recording\n",
      "Stop recording\n",
      "Full Recognized Text: \n",
      "GPT Advice: It looks like there may have been a mistake in your message. Could you please provide more details or context so I can offer you the best guidance possible?\n",
      "Original audio file deleted.\n"
     ]
    }
   ],
   "source": [
    "# 60초 동안 녹음\n",
    "recorder_thread = start_recording()\n",
    "time.sleep(60)\n",
    "stop_recording(recorder_thread)\n",
    "\n",
    "# STT 변환\n",
    "full_text = split_audio_and_send(\"temp.wav\")\n",
    "print(\"Full Recognized Text:\", full_text)\n",
    "\n",
    "# GPT에게 조언 요청\n",
    "advice = get_gpt_advice(full_text)\n",
    "print(\"GPT Advice:\", advice)\n",
    "\n",
    "# 원본 오디오 파일 삭제\n",
    "if os.path.exists(\"temp.wav\"):\n",
    "    os.remove(\"temp.wav\")\n",
    "    print(\"Original audio file deleted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sk-VsBg3163eZFviFyybH3yorlp8TE5WlPQOeh_qUjLReT3BlbkFJ-ZZNFazlMsQ2_JF28W1TIgfbG9_B_a7nnASC8VBnYA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "client = OpenAI(api_key='sk-VsBg3163eZFviFyybH3yorlp8TE5WlPQOeh_qUjLReT3BlbkFJ-ZZNFazlMsQ2_JF28W1TIgfbG9_B_a7nnASC8VBnYA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Conversation Guideline:\n",
      "Conversation Guideline for Elderly Care Services:\n",
      "\n",
      "Step 1: Introduction and Establishing Rapport\n",
      "1. Start by introducing yourself and your role in the welfare services.\n",
      "2. Greet the elderly individual warmly and ask how they are feeling today.\n",
      "3. Establish rapport by showing genuine interest and empathy towards their well-being.\n",
      "\n",
      "Step 2: Understanding the Elderly Individual's Needs\n",
      "4. Ask the elderly individual about their current living situation and any challenges they may be facing.\n",
      "5. Inquire about their daily activities and routines to understand their lifestyle better.\n",
      "6. Explore any health issues or medical conditions they may have and how it impacts their daily life.\n",
      "7. Discuss their social support system and if they have any caregivers or family members assisting them.\n",
      "\n",
      "Step 3: Discussing Available Elderly Care Services\n",
      "8. Explain the different types of elderly care services available such as home care, assisted living, or nursing homes.\n",
      "9. Provide information on the benefits and features of each type of service to help the individual make an informed decision.\n",
      "10. Discuss the eligibility criteria, costs, and funding options for the elderly care services.\n",
      "\n",
      "Step 4: Assessing the Elderly Individual's Preferences and Needs\n",
      "11. Ask the elderly individual about their preferences regarding the type of care they would like to receive.\n",
      "12. Inquire about their specific needs and requirements to tailor the care services accordingly.\n",
      "13. Discuss any cultural or religious considerations that may impact their care preferences.\n",
      "\n",
      "Step 5: Addressing Concerns and Questions\n",
      "14. Encourage the elderly individual to ask any questions or express any concerns they may have about the care services.\n",
      "15. Provide clarity and reassurance on any uncertainties or doubts they may have.\n",
      "16. Offer additional resources or support services to address specific concerns if needed.\n",
      "\n",
      "Step 6: Creating a Care Plan\n",
      "17. Collaborate with the elderly individual to create a personalized care plan that meets their needs and preferences.\n",
      "18. Discuss the roles and responsibilities of the caregivers or service providers involved in the care plan.\n",
      "19. Set clear goals and objectives for the care plan to ensure the elderly individual's well-being and comfort.\n",
      "\n",
      "Step 7: Follow-Up and Support\n",
      "20. Schedule a follow-up meeting to review the care plan and make any necessary adjustments.\n",
      "21. Provide contact information for ongoing support and assistance with any issues or questions that may arise.\n",
      "22. Express your commitment to ensuring the elderly individual's satisfaction and well-being throughout the care process.\n",
      "\n",
      "Remember to approach the\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_conversation_guideline(user_input, target_audience):\n",
    "    \"\"\"\n",
    "    사용자 입력과 대상에 맞춘 대화 가이드라인을 GPT를 통해 생성하는 함수\n",
    "\n",
    "    Args:\n",
    "        user_input (str): 사용자로부터 입력받은 복지 관련 질문 또는 주제\n",
    "        target_audience (str): 복지 대상 (예: 노인, 장애인 등)\n",
    "    \n",
    "    Returns:\n",
    "        str: GPT로 생성된 대화 가이드라인\n",
    "    \"\"\"\n",
    "    \n",
    "    # GPT-3.5 모델에게 보낼 프롬프트 설정\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in welfare services.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Create a conversation guideline for {target_audience} welfare services. The topic is '{user_input}'. Provide a structured dialogue guide with helpful questions and steps to follow.\"}\n",
    "    ]\n",
    "    \n",
    "    # OpenAI API를 통해 응답 생성\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",  # Chat-based GPT 모델 설정\n",
    "        messages=messages,\n",
    "        max_tokens=500,  # 생성할 응답의 최대 토큰 수\n",
    "        temperature=0.7,  # 창의성 설정 (0.0 ~ 1.0)\n",
    "        top_p=1.0,  # 확률 분포를 기반으로 한 선택의 다양성\n",
    "        n=1  # 결과 개수\n",
    "    )\n",
    "    \n",
    "    # 결과 반환 (content 속성을 직접 사용)\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# 사용자 입력 예시\n",
    "user_input = \"elderly care services\"\n",
    "target_audience = \"elderly\"\n",
    "\n",
    "# 대화 가이드라인 생성\n",
    "guideline = generate_conversation_guideline(user_input, target_audience)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Generated Conversation Guideline:\")\n",
    "print(guideline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Real-Time Response:\n",
      "무릎이 계속 아프시다니, 정말 힘드시겠네요. 병원에 가보시는 것이 좋은 선택일 수 있어요. 최근에 병원에 가실 때의 상황이 궁금하네요. 혹시 무엇 때문에 무릎이 아프신 건가요? 함께 대화해보면 무릎 통증을 완화할 수 있는 방법에 대해 이야기해볼 수도 있겠죠. 함께 건강을 챙기는 것이 중요하니까요.\n"
     ]
    }
   ],
   "source": [
    "def generate_real_time_conversation_response(user_input, conversation_context):\n",
    "    \"\"\"\n",
    "    실시간 대화를 위한 GPT 대화 응답 생성 함수\n",
    "\n",
    "    Args:\n",
    "        user_input (str): 상대방이 말한 대화 내용\n",
    "        conversation_context (str): 대화의 전체 흐름과 맥락 (이전 대화 내용)\n",
    "    \n",
    "    Returns:\n",
    "        str: GPT로 생성된 실시간 응답\n",
    "    \"\"\"\n",
    "    \n",
    "    # GPT 모델에 보낼 프롬프트 설정\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"당신은 사회복지 서비스 전문가입니다. 상대방의 말에 맞춰 적절하고 따뜻한 응답을 생성합니다.\"},\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": f\"\"\"\n",
    "            이전 대화 내용: '{conversation_context}'\n",
    "            상대방이 말한 내용: '{user_input}'\n",
    "            \n",
    "            상대방의 말에 적절하게 응답해 주세요. 응답은 상대방의 감정 상태를 고려하고, 필요한 경우 조언이나 추가 질문을 포함하여 대화가 자연스럽게 이어질 수 있도록 해 주세요.\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # OpenAI API 호출\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",  # 모델 설정\n",
    "        messages=messages,\n",
    "        max_tokens=500,  # 생성할 응답의 최대 토큰 수\n",
    "        temperature=0.7,  # 창의성 설정\n",
    "        top_p=1.0,  # 확률 분포 기반 선택\n",
    "        n=1  # 생성할 결과 개수\n",
    "    )\n",
    "    \n",
    "    # 생성된 응답 반환\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# 대화의 맥락 예시\n",
    "conversation_context = \"안녕하세요, 오늘 기분이 어떠신가요? 조금 피곤하지만 괜찮아요.\"\n",
    "\n",
    "# 상대방의 실시간 발언\n",
    "user_input = \"무릎이 계속 아프면 병원에 가보시는 게 좋을 것 같아요. 혹시 최근에 병원에 가신 적 있나요?\"\n",
    "\n",
    "# 실시간 대화 응답 생성\n",
    "response = generate_real_time_conversation_response(user_input, conversation_context)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Generated Real-Time Response:\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
